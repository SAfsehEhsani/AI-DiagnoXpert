# AI-DiagnoXpert
# A LLM-Powered Medical Insight & Diagnostic Assistant

AI DiagnoXpert is a Generative AI-driven medical assistant that delivers real-time, intelligent responses to medical queries, including symptoms, disease understanding, drug interactions, and preliminary diagnostics. 
Built for medical students, healthcare professionals, and curious patients, it leverages cutting-edge LLMs and high-speed Groq inference to simulate expert-level assistance with conversational ease.

# ğŸ¯ Project Aim
To empower users with a smart, accessible, and reliable AI healthcare assistant that explains complex medical concepts, offers diagnostics support, and references trusted medical knowledge â€” in real-time.

# ğŸ§  Key Features
ğŸ’¬ Natural Medical Q&A â€“ Ask anything related to symptoms, conditions, or medications.

âš¡ Real-Time Inference â€“ Powered by Groq's ultra-fast LLM backend for minimal response lag.

ğŸ§¾ Symptom-to-Diagnosis Support â€“ Helps identify probable conditions based on user-described symptoms.

ğŸ’Š Drug Info Assistant â€“ Explains usage, dosage, and interactions for common medications.

ğŸ“š Context-Rich Explanations â€“ Uses medical embeddings and context to generate accurate, user-friendly answers.

ğŸŒ RAG-Enhanced Option (Future) â€“ For up-to-date research-based responses from verified sources (e.g., MedlinePlus, WHO).


# ğŸ› ï¸ Tech Stack
# Component	Technologies Used

ğŸ’¡ Core Logic	Python, LangChain
ğŸ¤– LLMs	Groq (Mixtral), llama , gemma
ğŸŒ Web Interface	Streamlit
ğŸ” Reasoning Flow	Retrieval-Augmented Generation (planned)
ğŸ“ Architecture	Modular, Extensible API-ready structure

# ğŸš€ How It Works
User enters a query (e.g., "I have chest pain and dizziness")

Prompt pipeline classifies the query type (symptom, drug, condition)

LLM engine (Groq Mixtral / llama / gemma ) processes the enriched context

Response returned with a medically sound explanation and next-step suggestions

# Check Demo


